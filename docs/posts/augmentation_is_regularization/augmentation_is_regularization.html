<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.543">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tom Shlomo">
<meta name="dcterms.date" content="2024-01-15">
<meta name="description" content="On the equivalence of training data augmentation and quadratic regularization for linear models - a very useful (but not well known) result.">

<title>Tom Shlomo’s Blog - Augmentation is Regularization</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/quarto-contrib/academicons-1.9.2/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/academicons-1.9.2/size.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Tom Shlomo’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tom-shlomo/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/tomshlomo"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://scholar.google.com/citations?user=ZJSZgpwAAAAJ&amp;hl=en"> 
<span class="menu-text"><i class="ai  ai-google-scholar ai-Large"></i></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Augmentation is Regularization</h1>
                  <div>
        <div class="description">
          On the equivalence of training data augmentation and quadratic regularization for linear models - a very useful (but not well known) result.
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Tom Shlomo </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">January 15, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#notation" id="toc-notation" class="nav-link active" data-scroll-target="#notation">Notation</a></li>
  <li><a href="#ordinary-least-squares-ols" id="toc-ordinary-least-squares-ols" class="nav-link" data-scroll-target="#ordinary-least-squares-ols">Ordinary least squares (OLS)</a></li>
  <li><a href="#augmented-least-squares" id="toc-augmented-least-squares" class="nav-link" data-scroll-target="#augmented-least-squares">Augmented least squares</a></li>
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression">Ridge regression</a></li>
  <li><a href="#example" id="toc-example" class="nav-link" data-scroll-target="#example">Example</a></li>
  <li><a href="#beyond-least-squares" id="toc-beyond-least-squares" class="nav-link" data-scroll-target="#beyond-least-squares">Beyond least squares</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>Training data augmentation enhances the training dataset by applying transformations to existing training data instances. The specific transformations vary depending on the type of data involved, and this flexibility allows to leverage domain knowledge, such as known invariants, effectively. The goal is to introduce variability and increase the diversity of the training set, allowing the model to better generalize to unseen data and exhibit improved robustness. Despite the advantages, training data augmentation introduces an inherent computational cost: the increased volume of data requires additional computational resources, impacting both training time and memory requirements.</p>
<p>As we will show below, for linear models with the sum of squares loss, training data augmentation is equivalent to adding quadratic regularization term, which implies that the computational cost of fitting a model to an augmented dataset is the same as using no augmentation at all!</p>
<p>This link between augmentation and regularization is useful in the other direction as well: it gives a concrete interpretation to the value of regularization hyperparameters, and can be used to avoid costly hyperparameters tuning (<code>np.logspace(-6, 6, 100)</code> much?), and to design regularizers that are more appropriate to the data than the simple ones (i.e sum of squares regularization used in ridge regression).</p>
<section id="notation" class="level2">
<h2 class="anchored" data-anchor-id="notation">Notation</h2>
<p>Suppose we have a training data set comprised of <span class="math inline">\(n\)</span> pairs <span class="math inline">\(x_i,\,y_i\)</span> for <span class="math inline">\(i=0, \dots, n-1\)</span>, where <span class="math inline">\(x_i\)</span> is the <span class="math inline">\(d\)</span> dimensional feature vector of the <span class="math inline">\(i\)</span>’th training data, and <span class="math inline">\(y_i\)</span> is the corresponding label. Here we will assume <span class="math inline">\(y_i \in \mathrm{R}\)</span>, however our results can be easily extended to the vector-labeled (aka multi-output) case. We will also denote by <span class="math inline">\(X\)</span> the <span class="math inline">\(n\)</span>-by-<span class="math inline">\(d\)</span> matrix with rows <span class="math inline">\(x_0^T, \dots, x_{n-1}^T\)</span> and by <span class="math inline">\(y\)</span> the <span class="math inline">\(n\)</span>-vector with entries <span class="math inline">\(y_0, \dots, y_{n-1}\)</span>.</p>
<p>Let <span class="math inline">\(a:\mathrm{R}^d \times \mathcal{P}  \mapsto \mathrm{R}^d\)</span> denote the augmentation function that given the augmentation params <span class="math inline">\(p \in \mathcal{P}\)</span>, maps a feature vector <span class="math inline">\(x\)</span> to a transformed feature vector. The augmentation parameters <span class="math inline">\(p\)</span> are usually sampled randomly from a given distribution. For example, for image data, <span class="math inline">\(a\)</span> is often a composition of small shifts, rotations, brightness changes, etc. while <span class="math inline">\(p\)</span> specifies the amount of shifting, rotation and brightness change.</p>
</section>
<section id="ordinary-least-squares-ols" class="level2">
<h2 class="anchored" data-anchor-id="ordinary-least-squares-ols">Ordinary least squares (OLS)</h2>
<p>Let’s quickly discuss OLS so we can compare it’s equations with the augmented version we will derive after.<br>
To fit an OLS model, we find a vector of coefficients <span class="math inline">\(\theta_\text{OLS}\)</span> that minimizes the sum of squared training errors: <span class="math display">\[\begin{align*}
    \theta_\text{OLS} &amp;:= \text{argmin} _\theta \sum_{i=0} ^{n-1} \left(
    x_i ^T \theta - y_i
    \right) ^2
    \\&amp;= \text{argmin} _\theta \| X \theta - y \|^2 \tag{1}
\end{align*}\]</span> To solve the optimization problem (1), we solve the equation <span class="math inline">\(X^TX \theta_\text{OLS} = X^T y\)</span>, which has time complexity <span class="math inline">\(O(n d^2)\)</span>.</p>
</section>
<section id="augmented-least-squares" class="level2">
<h2 class="anchored" data-anchor-id="augmented-least-squares">Augmented least squares</h2>
<p>We will now fit a model by finding coefficients <span class="math inline">\(\theta_\text{ALS}\)</span> that minimize the expected error over the augmented training dataset: <span class="math display">\[\begin{align*}
    \theta_\text{ALS} &amp;:= \text{argmin} _\theta \mathrm{E}  
    \left[
    \sum_{i=0} ^{n-1} \left(
    a\left(x_i, p_i\right) ^T \theta - y_i
    \right) ^2
    \right], \tag{2}
\end{align*}\]</span> where the expectation is over <span class="math inline">\(p_0,\dots, p_{n-1}\)</span>, the random augmentation parameters. As we will see below, <span class="math inline">\(\theta_\text{ALS}\)</span> depends on <span class="math inline">\(a\)</span> and the distribution of <span class="math inline">\(p\)</span> only through the 2nd order moments, which we denote by <span class="math display">\[\begin{align*}
    \mu_i &amp;:= \mathrm{E} \left[a(x_i, p_i) \right]\\
    R_i &amp;:= \mathrm{C}\text{ov} \left[ a(x_i, p_i) \right].
\end{align*}\]</span></p>
<p>Continuing from (2), we use the standard trick of subtracting and adding the mean: <span class="math display">\[\begin{align*}
    \theta_\text{ALS} &amp;= \text{argmin} _\theta \mathrm{E}  
    \left[
        \sum_{i=0} ^{n-1} \left(
            \left(
                \mu_i^T \theta - y_i
            \right)
            + \left(
                a\left(x_i, p_i\right) -
                \mu_i
            \right)^T\theta
        \right) ^2
    \right]
\end{align*}\]</span> Note that the first term $ ( _i^T - y_i ) $ is deterministic, while the second term $ ( a(x_i, p_i) - _i )^T $ has zero mean. Therefore <span class="math display">\[\begin{align*}
    \theta_\text{ALS} &amp;= \text{argmin} _\theta
    \sum_{i=0} ^{n-1}
        \left(
            \mu_i^T \theta - y_i
        \right)
        +
        \mathrm{E} \left[\left(
            \left(
                a\left(x_i, p_i\right) -
                \mu_i
            \right)^T\theta
        \right)^2 \right] \\
    &amp;= \text{argmin} _\theta
    \| M \theta - y\|^2 + \theta ^T R \theta,
    \tag{3}
\end{align*}\]</span> where <span class="math inline">\(M\)</span> is the <span class="math inline">\(n\)</span>-by-<span class="math inline">\(d\)</span> matrix whose rows are <span class="math inline">\(\mu_0^T, \dots, \mu_{n-1}^T\)</span>, and <span class="math display">\[
R := \sum_{i=0} ^{n-1} R_i.
\]</span> Equation (3) shows exactly what we set to prove - fitting a model on augmented training dataset, is equivalent to fitting a non-augmented, but quadratically regularized, least squares model. We just replace <span class="math inline">\(X\)</span> with it’s mean, and use the sum of all covariances as the regularization matrix.</p>
<p>To solve the optimization problem (3), we solve the equation <span class="math inline">\((X^T X + R) \theta_\text{ALS} = X^T y\)</span>, which has the same <span class="math inline">\(O(n d^2)\)</span> complexity as OLS.</p>
</section>
<section id="ridge-regression" class="level2">
<h2 class="anchored" data-anchor-id="ridge-regression">Ridge regression</h2>
<p>Ride regression (aka Tykhonov regularization) has the form (3) with <span class="math inline">\(M=X\)</span> and <span class="math inline">\(R=\lambda I\)</span>. As an augmentation, it can be interpreted as follows: perturb each feature vector by a zero mean noise, with variance <span class="math inline">\(\lambda/n\)</span>, uncorrelated across features.<br>
This interpretation of <span class="math inline">\(\lambda\)</span> can be used to set it (at least roughly): just think what level of perturbation <span class="math inline">\(\sigma\)</span> is reasonable for your features, and set <span class="math inline">\(\lambda = n \sigma^2\)</span>.<br>
This also shows that when different feature are scaled differently, ridge regression is perhaps not the best fit. A standard deviation of 100 might be reasonable for a feature with values in the order of millions, but it is probably not suitable for a feature with values in the order of 1. In these cases, we may use a diagonal <span class="math inline">\(R\)</span>: <span class="math display">\[\begin{align*}
    R= n \, \text{diag} \left(
        \sigma_0^2, \dots, \sigma_{d-1}^2
    \right)
\end{align*}\]</span> where <span class="math inline">\(\sigma_i\)</span> is the standard deviation of the perturbation of feature <span class="math inline">\(i\)</span>.</p>
<p>Another option is to scale the transformations before fit, e.g using sklearn’s <code>StandardScaler</code>. With all features scaled to have unit variance, setting <span class="math inline">\(\lambda = n \, 10 ^{-6}\)</span> is a sensible rule of thumb, as it is often reasonable to assume a <span class="math inline">\(0.1\%\)</span> perturbation.</p>
<p>Note that often the model includes an intercept (aka constant) term by adding a column of ones to <span class="math inline">\(X\)</span>. Since this column remain unchanged through any augmenting transformation, the corresponding row and column of <span class="math inline">\(R\)</span> should be all zeros.</p>
</section>
<section id="example" class="level2">
<h2 class="anchored" data-anchor-id="example">Example</h2>
<p>For the example we are gonna use the <a href="https://www.kaggle.com/datasets/harlfoxem/housesalesprediction/data">House Sales in King County, USA dataset</a>. Each row describes a house, sold between May 2014 and May 2015. Our goal will be to predict the log price given features like number of rooms, area, and geography.</p>
<p>Note: several decisions outlined below weren’t necessarily the most effective,;, rather, they were chosen to showcase different modelling techniques in the context of augmentation via regularization.</p>
<p>Let’s begin by importing everything we will need, loading our data, and adding some columns.</p>
<div id="cell-7" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Callable, Hashable, Self</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.typing <span class="im">import</span> NDArray</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> scipy</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression, RidgeCV</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> r2_score</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>Array <span class="op">=</span> NDArray[np.float64]</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data/kc_house_data.csv.zip"</span>, parse_dates<span class="op">=</span>[<span class="st">"date"</span>])</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"long_scaled"</span>] <span class="op">=</span> df[<span class="st">"long"</span>] <span class="op">*</span> np.mean(</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    np.<span class="bu">abs</span>(np.cos(df[<span class="st">"lat"</span>] <span class="op">*</span> np.pi <span class="op">/</span> <span class="dv">180</span>))</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>)  <span class="co"># earth-curvature correction for (approximate) distance calculations</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>df.describe()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">date</th>
<th data-quarto-table-cell-role="th">price</th>
<th data-quarto-table-cell-role="th">bedrooms</th>
<th data-quarto-table-cell-role="th">bathrooms</th>
<th data-quarto-table-cell-role="th">sqft_living</th>
<th data-quarto-table-cell-role="th">sqft_lot</th>
<th data-quarto-table-cell-role="th">floors</th>
<th data-quarto-table-cell-role="th">waterfront</th>
<th data-quarto-table-cell-role="th">view</th>
<th data-quarto-table-cell-role="th">...</th>
<th data-quarto-table-cell-role="th">sqft_above</th>
<th data-quarto-table-cell-role="th">sqft_basement</th>
<th data-quarto-table-cell-role="th">yr_built</th>
<th data-quarto-table-cell-role="th">yr_renovated</th>
<th data-quarto-table-cell-role="th">zipcode</th>
<th data-quarto-table-cell-role="th">lat</th>
<th data-quarto-table-cell-role="th">long</th>
<th data-quarto-table-cell-role="th">sqft_living15</th>
<th data-quarto-table-cell-role="th">sqft_lot15</th>
<th data-quarto-table-cell-role="th">long_scaled</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>2.161300e+04</td>
<td>21613</td>
<td>2.161300e+04</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>2.161300e+04</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>...</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
<td>21613.000000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">mean</td>
<td>4.580302e+09</td>
<td>2014-10-29 04:38:01.959931648</td>
<td>5.400881e+05</td>
<td>3.370842</td>
<td>2.114757</td>
<td>2079.899736</td>
<td>1.510697e+04</td>
<td>1.494309</td>
<td>0.007542</td>
<td>0.234303</td>
<td>...</td>
<td>1788.390691</td>
<td>291.509045</td>
<td>1971.005136</td>
<td>84.402258</td>
<td>98077.939805</td>
<td>47.560053</td>
<td>-122.213896</td>
<td>1986.552492</td>
<td>12768.455652</td>
<td>-82.471784</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">min</td>
<td>1.000102e+06</td>
<td>2014-05-02 00:00:00</td>
<td>7.500000e+04</td>
<td>0.000000</td>
<td>0.000000</td>
<td>290.000000</td>
<td>5.200000e+02</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>290.000000</td>
<td>0.000000</td>
<td>1900.000000</td>
<td>0.000000</td>
<td>98001.000000</td>
<td>47.155900</td>
<td>-122.519000</td>
<td>399.000000</td>
<td>651.000000</td>
<td>-82.677673</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">25%</td>
<td>2.123049e+09</td>
<td>2014-07-22 00:00:00</td>
<td>3.219500e+05</td>
<td>3.000000</td>
<td>1.750000</td>
<td>1427.000000</td>
<td>5.040000e+03</td>
<td>1.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>1190.000000</td>
<td>0.000000</td>
<td>1951.000000</td>
<td>0.000000</td>
<td>98033.000000</td>
<td>47.471000</td>
<td>-122.328000</td>
<td>1490.000000</td>
<td>5100.000000</td>
<td>-82.548783</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">50%</td>
<td>3.904930e+09</td>
<td>2014-10-16 00:00:00</td>
<td>4.500000e+05</td>
<td>3.000000</td>
<td>2.250000</td>
<td>1910.000000</td>
<td>7.618000e+03</td>
<td>1.500000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>1560.000000</td>
<td>0.000000</td>
<td>1975.000000</td>
<td>0.000000</td>
<td>98065.000000</td>
<td>47.571800</td>
<td>-122.230000</td>
<td>1840.000000</td>
<td>7620.000000</td>
<td>-82.482651</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">75%</td>
<td>7.308900e+09</td>
<td>2015-02-17 00:00:00</td>
<td>6.450000e+05</td>
<td>4.000000</td>
<td>2.500000</td>
<td>2550.000000</td>
<td>1.068800e+04</td>
<td>2.000000</td>
<td>0.000000</td>
<td>0.000000</td>
<td>...</td>
<td>2210.000000</td>
<td>560.000000</td>
<td>1997.000000</td>
<td>0.000000</td>
<td>98118.000000</td>
<td>47.678000</td>
<td>-122.125000</td>
<td>2360.000000</td>
<td>10083.000000</td>
<td>-82.411796</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">max</td>
<td>9.900000e+09</td>
<td>2015-05-27 00:00:00</td>
<td>7.700000e+06</td>
<td>33.000000</td>
<td>8.000000</td>
<td>13540.000000</td>
<td>1.651359e+06</td>
<td>3.500000</td>
<td>1.000000</td>
<td>4.000000</td>
<td>...</td>
<td>9410.000000</td>
<td>4820.000000</td>
<td>2015.000000</td>
<td>2015.000000</td>
<td>98199.000000</td>
<td>47.777600</td>
<td>-121.315000</td>
<td>6210.000000</td>
<td>871200.000000</td>
<td>-81.865195</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">std</td>
<td>2.876566e+09</td>
<td>NaN</td>
<td>3.671272e+05</td>
<td>0.930062</td>
<td>0.770163</td>
<td>918.440897</td>
<td>4.142051e+04</td>
<td>0.539989</td>
<td>0.086517</td>
<td>0.766318</td>
<td>...</td>
<td>828.090978</td>
<td>442.575043</td>
<td>29.373411</td>
<td>401.679240</td>
<td>53.505026</td>
<td>0.138564</td>
<td>0.140828</td>
<td>685.391304</td>
<td>27304.179631</td>
<td>0.095033</td>
</tr>
</tbody>
</table>

<p>8 rows × 22 columns</p>
</div>
</div>
</div>
<p>We will want a polynomial (rather than linear) dependency on the age of the house:</p>
<div id="cell-9" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>df[<span class="st">"age"</span>] <span class="op">=</span> df[<span class="st">"date"</span>].dt.year <span class="op">-</span> df[<span class="st">"yr_built"</span>]</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>age_cols <span class="op">=</span> [<span class="st">"age"</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> power <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">5</span>):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> <span class="ss">f"age ^ </span><span class="sc">{</span>power<span class="sc">}</span><span class="ss">"</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    df[col] <span class="op">=</span> df[<span class="st">"age"</span>] <span class="op">**</span> power</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    age_cols.append(col)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We do a 10-90 train-test split to demonstrate the effectiveness of augmentation when we have little data.</p>
<div id="cell-11" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> np.log(df[<span class="st">"price"</span>])</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">"price"</span>])</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>x_train, x_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.9</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>x_train<span class="sc">.</span>shape<span class="op">=</span><span class="sc">}</span><span class="ss">, </span><span class="sc">{</span>x_test<span class="sc">.</span>shape<span class="op">=</span><span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>x_train.shape=(2161, 25), x_test.shape=(19452, 25)</code></pre>
</div>
</div>
<p>There is no reason to expect a linear relationship between the house geographical coordinates and it’s price.<br>
However, we do expect a strong dependency between price and location in the sense that houses with similar features should share similar prices when located in close geographical proximity.<br>
One way to model this is to cluster the data geographically, and tag each house with the cluster it belongs to using one hot encoding:</p>
<div id="cell-13" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># We need this class mainly since the transform method of sklearn's k-means class yields cluster centers, and we want one hot encoding.</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> OneHotEncodedKMeansTransformer:</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, k: <span class="bu">int</span>, columns: <span class="bu">list</span>[<span class="bu">str</span>], name: <span class="bu">str</span>) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.columns <span class="op">=</span> columns</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.k <span class="op">=</span> k</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.name <span class="op">=</span> name</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X: pd.DataFrame) <span class="op">-&gt;</span> Self:</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kmeans_ <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="va">self</span>.k, n_init<span class="op">=</span><span class="st">"auto"</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.kmeans_.fit(X[<span class="va">self</span>.columns])</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> column_names(<span class="va">self</span>) <span class="op">-&gt;</span> <span class="bu">list</span>[<span class="bu">str</span>]:</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> [<span class="ss">f"</span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>name<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">"</span> <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.k)]</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> transform(<span class="va">self</span>, X: pd.DataFrame):</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        cluster_index <span class="op">=</span> <span class="va">self</span>.kmeans_.predict(X[<span class="va">self</span>.columns])</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> pd.concat(</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>            [</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>                X,</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>                pd.DataFrame(</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>                    np.eye(<span class="va">self</span>.k)[cluster_index],</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>                    columns<span class="op">=</span><span class="va">self</span>.column_names(),</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>                    index<span class="op">=</span>X.index,</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>                ),</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            axis<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> clusters_adjacency_matrix(<span class="va">self</span>):</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        edges <span class="op">=</span> np.array(</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            scipy.spatial.Voronoi(<span class="va">self</span>.kmeans_.cluster_centers_).ridge_points</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        ).T</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>        a <span class="op">=</span> scipy.sparse.coo_matrix(</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>            (np.ones(edges.shape[<span class="dv">1</span>]), (edges[<span class="dv">0</span>], edges[<span class="dv">1</span>])),</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>            shape<span class="op">=</span>(<span class="va">self</span>.k, <span class="va">self</span>.k),</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a <span class="op">+</span> a.T</span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>kmeans_transformer <span class="op">=</span> OneHotEncodedKMeansTransformer(</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    k<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>    columns<span class="op">=</span>[<span class="st">"lat"</span>, <span class="st">"long_scaled"</span>],</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"geo_cluster"</span>,</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>x_train <span class="op">=</span> kmeans_transformer.fit(x_train).transform(x_train)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>x_test <span class="op">=</span> kmeans_transformer.transform(x_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We will evaluate our models by their R squared score. From a quick glance over Kaggle, it seems that sophisticated and advanced models (e.g XGBoost) can achieve a score of about 0.9. Let’s see if we can get there using a linear model.</p>
<div id="cell-15" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(model) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    y_train_pred <span class="op">=</span> model.fit(x_train, y_train).predict(x_train)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    r2_train <span class="op">=</span> r2_score(y_train, y_train_pred)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    y_test_pred <span class="op">=</span> model.predict(x_test)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    r2_test <span class="op">=</span> r2_score(y_test, y_test_pred)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>r2_train<span class="op">=</span><span class="sc">:.3f}</span><span class="ss">, </span><span class="sc">{</span>r2_test<span class="op">=</span><span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s start with a vanilla linear model, without any regularization/augmentations.</p>
<div id="cell-17" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>columns <span class="op">=</span> (</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="st">"bedrooms"</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="st">"bathrooms"</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">"floors"</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">"waterfront"</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"view"</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"condition"</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"grade"</span>,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_living"</span>,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_lot"</span>,</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_above"</span>,</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_basement"</span>,</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_lot15"</span>,</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_living15"</span>,</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> age_cols</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="op">+</span> kmeans_transformer.column_names()</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>columns_selector <span class="op">=</span> ColumnTransformer(</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    [(<span class="st">"selector"</span>, <span class="st">"passthrough"</span>, columns)],</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    remainder<span class="op">=</span><span class="st">"drop"</span>,</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    verbose_feature_names_out<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>).set_output(transform<span class="op">=</span><span class="st">"pandas"</span>)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>simple_linear <span class="op">=</span> Pipeline(</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"selector"</span>, columns_selector),</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"linear"</span>, LinearRegression(fit_intercept<span class="op">=</span><span class="va">False</span>)),</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>evaluate_model(simple_linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>r2_train=0.918, r2_test=0.862</code></pre>
</div>
</div>
<p>Not bad, but we do have some overfitting. Let’s see if we can improve generalization with regularization/augmentation. First we try ridge regression:</p>
<div id="cell-19" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>ridge <span class="op">=</span> Pipeline(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"selector"</span>, columns_selector),</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"scale"</span>, StandardScaler()),</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>        (</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>            <span class="st">"linear"</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>            RidgeCV(</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>                fit_intercept<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>                alphas<span class="op">=</span>x_train.shape[<span class="dv">0</span>] <span class="op">*</span> np.logspace(<span class="op">-</span><span class="dv">9</span>, <span class="op">-</span><span class="dv">2</span>, <span class="dv">100</span>),</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>            ),</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>evaluate_model(ridge)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>r2_train=0.918, r2_test=0.863</code></pre>
</div>
</div>
<p>That didn’t really help. That makes sense since using a diagonal regularization matrix doesn’t make sense for our correlated features.<br>
Let’s see if we can do better by using augmentations that are more appropriate for our data.</p>
<p>First let’s build a class for linear models with augmentation via regularization.<br>
We will pass to the constructor a callable that takes the input features and returns their mean and (sum of) covariance after the augmentation, since as we shown above these are all we need from the augmentations.<br>
Since often the transformations of different features are uncorrelated, it is convenient to specify features in groups, and assume zero covariance for features that are not in the same group (i.e a block diagonal covariance matrix).</p>
<div id="cell-21" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AugmentedLinearModel:</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        augmentation_moments: <span class="bu">list</span>[  <span class="co"># one item for each group of features</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>            <span class="bu">tuple</span>[</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>                <span class="bu">list</span>[Hashable],  <span class="co"># column names of features in the group</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>                Callable[[pd.DataFrame], <span class="bu">tuple</span>[Array, Array]],  <span class="co"># maps X to M and R</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>            ]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    ) <span class="op">-&gt;</span> <span class="va">None</span>:</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.augmentation_moments <span class="op">=</span> augmentation_moments</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X: pd.DataFrame, y: pd.Series) <span class="op">-&gt;</span> Self:</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        means, covs <span class="op">=</span> <span class="bu">zip</span>(</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>            <span class="op">*</span>(</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>                moments(X.loc[:, columns])</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> columns, moments <span class="kw">in</span> <span class="va">self</span>.augmentation_moments</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>        M <span class="op">=</span> np.hstack(means)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>        <span class="co"># https://scikit-learn.org/stable/developers/develop.html#estimated-attributes</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.R_ <span class="op">=</span> scipy.linalg.block_diag(<span class="op">*</span>covs)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.theta_ <span class="op">=</span> np.linalg.solve(M.T <span class="op">@</span> M <span class="op">+</span> <span class="va">self</span>.R_, M.T <span class="op">@</span> y)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X: pd.DataFrame) <span class="op">-&gt;</span> pd.Series:</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        cols <span class="op">=</span> [col <span class="cf">for</span> cols, _ <span class="kw">in</span> <span class="va">self</span>.augmentation_moments <span class="cf">for</span> col <span class="kw">in</span> cols]</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> X.loc[:, cols] <span class="op">@</span> <span class="va">self</span>.theta_</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here are the augmentations we are gonna use:<br>
With 10% probability, a bathroom is counted as half a bedroom.</p>
<div id="cell-23" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> bedrooms_bathrooms_moments(X: pd.DataFrame) <span class="op">-&gt;</span> <span class="bu">tuple</span>[Array, Array]:</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="op">-</span><span class="fl">0.5</span>])</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    mask <span class="op">=</span> X[[<span class="st">"bathrooms"</span>]] <span class="op">&gt;=</span> <span class="dv">1</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> np.where(mask, X <span class="op">+</span> p <span class="op">*</span> v, X)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    R <span class="op">=</span> p <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> p) <span class="op">*</span> np.outer(v, v) <span class="op">*</span> mask.values.<span class="bu">sum</span>()</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> M, R</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>augmentation_moments <span class="op">=</span> [([<span class="st">"bedrooms"</span>, <span class="st">"bathrooms"</span>], bedrooms_bathrooms_moments)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A 5% perturbation for the features<br>
<code>sqft_living, sqft_lot, sqft_above, sqft_basement, sqft_lot15, sqft_living15</code>, uncorrelated across the features.</p>
<div id="cell-25" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> relative_perturbation_moments(X: pd.DataFrame) <span class="op">-&gt;</span> <span class="bu">tuple</span>[Array, Array]:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X.values, np.<span class="bu">sum</span>(X.values<span class="op">**</span><span class="dv">2</span>) <span class="op">*</span> <span class="fl">0.05</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>augmentation_moments.extend(</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    ([column], relative_perturbation_moments)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> column <span class="kw">in</span> [</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_living"</span>,</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_lot"</span>,</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_above"</span>,</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_basement"</span>,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_lot15"</span>,</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">"sqft_living15"</span>,</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A perturbation of 0.01 for the features <code>floors, waterfront, view, condition, grade</code>, uncorrelated across the features</p>
<div id="cell-27" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> absolute_perturbation_moments(X: pd.DataFrame) <span class="op">-&gt;</span> <span class="bu">tuple</span>[Array, Array]:</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X.values, X.shape[<span class="dv">0</span>] <span class="op">*</span> <span class="fl">0.01</span><span class="op">**</span><span class="dv">2</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>augmentation_moments.extend(</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    ([column], absolute_perturbation_moments)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> column <span class="kw">in</span> [<span class="st">"floors"</span>, <span class="st">"waterfront"</span>, <span class="st">"view"</span>, <span class="st">"condition"</span>, <span class="st">"grade"</span>]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>perturbing <code>age</code> with a uniform distribution between -1 and 1. We need to calculate the moments for the power of age accordingly.</p>
<div id="cell-29" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> age_moments(X: pd.DataFrame) <span class="op">-&gt;</span> <span class="bu">tuple</span>[Array, Array]:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> X[[<span class="st">"age"</span>]].values <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    b <span class="op">=</span> X[[<span class="st">"age"</span>]].values <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    max_power <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    np1 <span class="op">=</span> np.arange(<span class="dv">2</span>, <span class="dv">2</span> <span class="op">*</span> max_power <span class="op">+</span> <span class="dv">2</span>)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># https://en.wikipedia.org/wiki/Continuous_uniform_distribution#Moments</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> (b<span class="op">**</span>np1 <span class="op">-</span> a<span class="op">**</span>np1) <span class="op">/</span> (np1 <span class="op">*</span> (b <span class="op">-</span> a))</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    mu_sum <span class="op">=</span> mu[:, <span class="dv">1</span>:].<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    mu <span class="op">=</span> mu[:, :max_power]</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> np.add.outer(np.arange(max_power), np.arange(max_power))</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> mu_sum[idx] <span class="op">-</span> mu.T <span class="op">@</span> mu</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mu, c</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>augmentation_moments.append((age_cols, age_moments))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And finally, with probability 50%, the geo cluster is changed to one of it’s neighbors.</p>
<div id="cell-31" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> geo_cluster_moments(X: pd.DataFrame) <span class="op">-&gt;</span> <span class="bu">tuple</span>[Array, Array]:</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    p <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    adj_mat <span class="op">=</span> kmeans_transformer.clusters_adjacency_matrix()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    P <span class="op">=</span> scipy.sparse.eye(adj_mat.shape[<span class="dv">0</span>]) <span class="op">*</span> p <span class="op">+</span> (adj_mat <span class="op">/</span> adj_mat.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">1</span>)) <span class="op">*</span> (</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        <span class="dv">1</span> <span class="op">-</span> p</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    )  <span class="co"># transition probabilities matrix</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    M <span class="op">=</span> scipy.sparse.csr_array(X.values) <span class="op">@</span> P</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># https://en.wikipedia.org/wiki/Multinomial_distribution#Matrix_notation</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    R <span class="op">=</span> scipy.sparse.diags(M.<span class="bu">sum</span>(axis<span class="op">=</span><span class="dv">0</span>)) <span class="op">-</span> M.T <span class="op">@</span> M</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> M.toarray(), R.toarray()</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>augmentation_moments.append((kmeans_transformer.column_names(), geo_cluster_moments))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le’t fit the augmented model and see how we did:</p>
<div id="cell-33" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>augmented_linear <span class="op">=</span> AugmentedLinearModel(augmentation_moments)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>evaluate_model(augmented_linear)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>r2_train=0.903, r2_test=0.882</code></pre>
</div>
</div>
<p>We managed to improve the test accuracy, and reduce overfit.</p>
</section>
<section id="beyond-least-squares" class="level2">
<h2 class="anchored" data-anchor-id="beyond-least-squares">Beyond least squares</h2>
<p>Is it possible to extend the result to models that use a non-quadratic loss (e.g logistic regression)? Well the proof heavily relies on that, so probably not, but let’s if we can at least can an approximate result using a 2nd order taylor approximation for the loss.</p>
<p>The goal is to (approximately) express <span class="math display">\[\begin{align*}
    \mathrm{E}  
    \left[
    \sum_{i=0} ^{n-1} l \left(
    a\left(x_i, p_i\right) ^T \theta \,;\, y_i
    \right)
    \right],
\end{align*}\]</span> as a sum of a non-augmented loss term, and a regularization term. Here, <span class="math inline">\(l(\hat{y}\,;\,y)\)</span> measures how bad is the prediction <span class="math inline">\(\hat{y}\)</span>, given the true value <span class="math inline">\(y\)</span> (the loss).<br>
For example, for logistic regression we use the logistic loss <span class="math display">\[
l(\hat{y}; y) = \log \left( 1 + \exp \left(-y \, \hat{y} \right) \right)
\]</span> (with <span class="math inline">\(y \in \{ -1, 1 \}\)</span>).<br>
Let’s expand <span class="math inline">\(l \left(
a\left(x_i, p_i\right) ^T \theta\,;\,y_i
\right)\)</span> around <span class="math inline">\(\mu_i ^T \theta\)</span> and simplify: <span class="math display">\[\begin{align*}
\mathrm{E}  
\left[
\sum_{i=0} ^{n-1} l \left(
a\left(x_i, p_i\right) ^T \theta \,;\, y_i
\right)
\right]
\approx
\sum_{i=0} ^{n-1} l(\mu_i ^T \theta\,;\,y_i) + \frac{1}{2}  l'' \left( \mu_i ^T \theta\,;\,y_i \right) \theta^T R \theta
\end{align*}\]</span> (the order-1 term vanishes as it has zero mean, similar to <a href="https://en.wikipedia.org/wiki/Delta_method#">the delta method</a>).<br>
So like in the least squares case, in the loss term we just replace each <span class="math inline">\(x\)</span> with it’s mean. But, the regularization term is not quadratic, since we have the second derivative factor which is not constant (unless the loss is quadratic…).</p>
<p>I use this result to tell myself that it is ok to select an <span class="math inline">\(R\)</span> for a quadratic regularization based on the covariance of an augmentation, as long as the covariance is small (usually correct for augmentations), and <span class="math inline">\(l''\)</span> is bounded (correct for logistic regression).</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>