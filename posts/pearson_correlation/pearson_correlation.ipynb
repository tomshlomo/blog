{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"A practical interpertation of the Pearson correlation coefficient\"\n",
        "author: \"Tom Shlomo\"\n",
        "date: \"2024-01-20\"\n",
        "categories: [machine learning]\n",
        "description: $\\rho=1$ means perfect positive correlation, $\\rho=-1$ means perfect negative correlation, $\\rho=0$ means no correlation. But what does $\\rho=0.72$ mean?\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My goal is to explain the Pearson correlation coefficient without using the word correlation, which is often used to describe it.\n",
        "\\\n",
        "One way is to just give the definition: the Pearson correlation coefficient of two random variables $X$ and $Y$ is\n",
        "$$\n",
        "\\rho = \\frac{\\sigma_{XY}}{\\sigma_X \\sigma_Y},\n",
        "$$\n",
        "where \n",
        "$\\sigma_X^2 =\\mathrm{E} (X - \\mu_X)^2$ is the variance of $X$, \n",
        "$\\sigma_Y^2 =\\mathrm{E} (Y - \\mu_Y)^2$ is the variance of $Y$, \n",
        "$\\sigma_{XY}=\\mathrm{E} (X - \\mu_X)(Y - \\mu_Y)$ is the covariance of $X$ and $Y$,\n",
        "$\\mu_x = \\mathrm{E} X$ is the mean of $X$,\n",
        "and $\\mu_Y = \\mathrm{E} Y$ is the mean of $Y$.\n",
        "\\\n",
        "But this is unsatisfying: why is this definition useful?\n",
        "\n",
        "Consider the problem of estimating $Y$ from an observation of $X$.\n",
        "It turns out that in the optimal linear estimator, *the number of standard deviations $Y$ is above it's mean is \n",
        "$\\rho$ times\n",
        "the number of standard deviations $X$ is above it's mean.*\n",
        " <!-- is $\\rho$ \n",
        " the \n",
        "The optimal linear estimat\n",
        "A more practical \n",
        "A more practical approach is \n",
        "Here is a more practical approach:\n",
        "Suppose you are given an observation of $X$ that is $n$ standard deviations away from it's mean and you want to estimate $Y$ using it.\n",
        "Then the optimal (in the mean squared error sense) linear estimation is $n \\rho$ standard deviations of $Y$ away from it's mean. -->\n",
        "\\\n",
        "In other words, $\\rho$ is the factor by which we shrink (and possibly flip) the deviation from the mean in one variable when we estimate the other.\n",
        "\\\n",
        "So for example, consider a population of people where\n",
        "height and weight are correlated with $rho=0.72$,\n",
        "heights are distributed with mean 170cm and std of 10cm,\n",
        "weights are distributed with mean 70Kg and std of 20Kg.\n",
        "If you know that the height of a certain person is 190cm,\n",
        "a good guess for it's weight is\n",
        "$ 70 + 2 * 0.72 * 20 = 98.8Kg $.\n",
        "<!-- \n",
        "$\\rho=0.72, \\mu_x = 4, \\sigma_x = 0.5, \\mu_y = 100, \\sigma_y = 10$ \n",
        "and we observe $X=5$, the estimate of $Y$ is \n",
        "$100 + 0.72 \\cdot 2 \\cdot 10 =114.4$ -->\n",
        "\n",
        "The proof is very simple. Since we are dealing with linear (actually, affine) estimators, we need to show that the $a$ and $b$ that would minimize \n",
        "$$\n",
        "\\text{MSE} := \\mathrm{E} \\left( \\hat{Y} - Y ^2 \\right) ^2,\n",
        "$$\n",
        "where $\\hat{Y} := a (X - \\mu_x) + b$,\n",
        "<!-- $$\n",
        "\\mathrm{E} \\left[ \\left(a (x - \\mu_x) + b - y \\right) ^ 2 \\right]\n",
        "$$ -->\n",
        "are $\\rho \\sigma_Y / \\sigma_X$ and $\\mu_Y$.\n",
        "\n",
        "The MSE is the sum of bias squared and variance.\n",
        "The variance doesn't depend on $b$, and the bias is\n",
        "$\\mathrm{E} \\left[ \\hat{Y} - Y \\right] = b - \\mu_Y$\n",
        "which doesn't depend on $a$.\n",
        "So we already know that $b=\\mu_Y$.\n",
        "To minimize the variance, we simplify\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\mathrm{Var}\\left[\\hat{Y} - Y\\right]\n",
        "&= \\mathrm{Var}\\left[a (X - \\mu_X) - Y\\right] \\\n",
        "&= \\mathrm{Var}\\left[a \\left(X - \\mu_X\\right) \\right] \n",
        "    + \\mathrm{Var}\\left[ Y\\right] \n",
        "    -2 \\mathrm{Cov}\\left[a \\left(X - \\mu_X\\right), Y\\right] \\\n",
        "&= \\sigma_x ^ 2 a^2 \n",
        "   + \\sigma_Y ^2\n",
        "   -2  \\sigma_{XY} a\n",
        "\\end{align*}\n",
        "$$\n",
        "This is just a parabola in $a$, so the optimal $a$ is\n",
        "$$\n",
        "\\frac{2 \\sigma_{XY}} {2 \\sigma_X ^2}\n",
        "=\n",
        "\\rho \\frac{\\sigma_Y } {\\sigma_X }\n",
        "$$\n",
        "(which is what we wanted to show).\n",
        "\n",
        "The estimator is unbiased, so it's MSE is equal to it's variance:\n",
        "$$\n",
        "\\text{MSE} = \\sigma_Y ^2 (1 - \\rho ^ 2).\n",
        "$$\n",
        "This equation gives another concrete interpretation of $\\rho$:\n",
        "*If $X$ and $Y$ are correlated with coefficient $\\rho$, observing $X$ will decrease the standard deviation of a $Y$ estimate by a factor of at least $\\sqrt{1 - \\rho^2}$.*\n",
        "\\\n",
        "\"at least\" since the the optimal linear estimator is equal or worse than the optimal estimator.\n",
        "\\\n",
        "In the example above, knowing the height decreases weight estimation error from 20Kg to $20  (1 - 0.72^2) = 9.6$ Kg.\n",
        "\n",
        "Notes:\n",
        "1. If $X$ and $Y$ are jointly Gaussian, the optimal linear estimator is also the optimal estimator.\n",
        "\n",
        "2. The \"mean\" in \"MSE\" is an average over the joint distribution of $X$ and $Y$, which is different than over the distribution of $Y$ given $X$, for which\n",
        "our estimator is not the optimal linear estimator (and biased).\\\n",
        "In our example, we estimated the weight to be 98.8Kg with variance $9.6^2$.\n",
        "It doesn't mean that if we will sample random people with height 190cm, we would get a mean weight of 98.8Kg and variance smaller than $9.6^2$.\n",
        "It means that if we sample random people, and estimate their weight from their height using the optimal linear estimator, our error will be zero on average, and with variance $9.6^2$.\n",
        "If we use the optimal estimator, the $9.6^2$ is an upper bound on the variance.\n",
        "\n",
        "3. The sentence \"$X$ and $Y$ are not correlated\" now has a concrete meaning: it means that the optimal linear estimator of $Y$ from $X$ will be the mean of $Y$, ignoring $X$ completely.\n",
        "\n",
        "4. The discussion above is \"Bayesian\", in the sense that it assumes you have some knowledge about the distribution of $X$ and $Y$.\n",
        "In practice usually get $n$ samples of $X$ and $Y$ pairs, and we use plug-in estimators to estimate the means, variances, and covariance, which we will then use build our $Y$ from $X$ linear estimator.\n",
        "\\\n",
        "Machine learning people would say: we can take the samples to train a linear regression model to predict $Y$ from $X$. It sounds better, more \"end-to-end\"y.\n",
        "But actually it gives exactly the same result (assuming we don't use [Bessel's correction](https://en.wikipedia.org/wiki/Bessel%27s_correction)):\n",
        "TODO: proof\n",
        "<!-- \n",
        "The optima\n",
        "The optimal $a=\\frac{2 \\sigma_{XY}} {2 \\sigma_X ^ 2}$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "a \n",
        "&= \\text{argmin}_{a'} \\mathrm{Var}\\left[\\hat{Y} - Y\\right] \\\n",
        "&= \\text{argmin}_{a'} \\mathrm{Var}\\left[a (X - \\mu_X) - Y\\right] \\\n",
        "&= \\text{argmin}_{a'} \n",
        "    \\mathrm{Var}\\left[a \\left(X - \\mu_X\\right) \\right] \n",
        "    + \\mathrm{Var}\\left[ Y\\right] \n",
        "    -2 \\mathrm{Cov}\\left[a \\left(X - \\mu_X\\right), Y\\right] \\\n",
        "&= \\text{argmin}_{a'} \n",
        "    a^2 \\sigma_x ^ 2\n",
        "    + \\sigma_Y ^2\n",
        "    -2 a \\sigma_{XY}\n",
        "\\end{align*}\n",
        "$$\n",
        "and the variance do\n",
        "We with expanding the MSE as the sum of the squared bias and variance\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\text{MSE} &=\n",
        "\\left(\\mathrm{E} \\left[\\hat{Y} - Y \\right] \\right)^2\n",
        "+ \\mathrm{Var} \\left[\\hat{Y} - Y \\right]\n",
        "\\&=\n",
        "b ^ 2\n",
        "+ \\mathrm{Var} \\left[a (x - \\mu_X) - Y \\right]\n",
        "\\end{align*}\n",
        "$$ -->\n",
        "\n",
        "<!-- \n",
        "Suppose the Pearson correlation coefficient is $\\rho$, \n",
        "and you wish to estimate $Y$ based on a given observation of $X$\n",
        "that is $n$ standard deviations away from the mean.\n",
        "The optimal linear estimate is $n \\rho$ standard deviations away from the mean.\n",
        "\n",
        "If the observation of $X$ is $n$\n",
        "It turns out that the optimal linear estimation is $\\rho$ \n",
        "then the optimal linear estimation of $Y$ given a sample of $X$ is\n",
        "then the optimal linear estimation of $Y$ from $X$ is obtained by \n",
        "1. Calculate by how many standard deviations the sampled $X$ is above it's mean.\n",
        "2. multiply by $\\rho$.\n",
        "3. This is by how many standard deviations the estimate of $Y$ is above it's mean. -->\n",
        "<!-- $$\n",
        "\\begin{align*}\n",
        "\\mathrm{E} \\left[ \\left(a (x - \\mu_x) + b - y \\right) ^ 2 \\right]\n",
        "&= \n",
        "a ^ 2 \\mathrm{E} \\left[ \\left( x - \\mu_x \\right) ^ 2 \\right]\n",
        "+\n",
        "\\mathrm{E} \\left[ \\left(b - y \\right) ^ 2 \\right]\n",
        "+\n",
        "a \\mathrm{E} \\left[ \\left(x - \\mu_x\\right) \\left(b - y \\right) \\right]\n",
        "\\&=\n",
        "a ^ 2 \\sigma_x ^2\n",
        "+\n",
        "\\sigma_y ^ 2\n",
        "+\n",
        "a \\, \\sigma_{xy}\n",
        "\\end{align*}\n",
        "$$ -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
